{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["GnMcPnz5_hkE"],"authorship_tag":"ABX9TyMamvy//S90Kzeo2RmJPKIT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Data reading"],"metadata":{"id":"EjIFN7PPYyVT"}},{"cell_type":"code","execution_count":93,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cwjp9GV4uxQw","executionInfo":{"status":"ok","timestamp":1718101482491,"user_tz":-480,"elapsed":436,"user":{"displayName":"Palash","userId":"17952405708644180763"}},"outputId":"ac6e221d-58e1-4222-b864-3814ba20f797"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-06-11 10:24:41--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1115394 (1.1M) [text/plain]\n","Saving to: ‘input.txt.4’\n","\n","\rinput.txt.4           0%[                    ]       0  --.-KB/s               \rinput.txt.4         100%[===================>]   1.06M  --.-KB/s    in 0.04s   \n","\n","2024-06-11 10:24:42 (26.7 MB/s) - ‘input.txt.4’ saved [1115394/1115394]\n","\n"]}],"source":["!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"]},{"cell_type":"code","source":["with open('input.txt', 'r', encoding='utf-8') as f:\n","    text = f.read()"],"metadata":{"id":"dqRXawC0u_-x","executionInfo":{"status":"ok","timestamp":1718101483078,"user_tz":-480,"elapsed":15,"user":{"displayName":"Palash","userId":"17952405708644180763"}}},"execution_count":94,"outputs":[]},{"cell_type":"code","source":["print(len(text), len(text.split()), len(set(text)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B1zVOVnvvE7T","executionInfo":{"status":"ok","timestamp":1718101483078,"user_tz":-480,"elapsed":15,"user":{"displayName":"Palash","userId":"17952405708644180763"}},"outputId":"4809e6e6-1b0d-4be3-f0ba-6447f9498d12"},"execution_count":95,"outputs":[{"output_type":"stream","name":"stdout","text":["1115394 202651 65\n"]}]},{"cell_type":"markdown","source":["# Data processing"],"metadata":{"id":"2dZjwcC8Y-vk"}},{"cell_type":"code","source":["chars = sorted(set(text))\n","vocab_size = len(chars)\n","print(f\"{vocab_size=}\\n<S>{'|'.join(chars)}<E>\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JnaUgM6HvHHB","executionInfo":{"status":"ok","timestamp":1718101483078,"user_tz":-480,"elapsed":13,"user":{"displayName":"Palash","userId":"17952405708644180763"}},"outputId":"b76096de-88ba-4875-c5df-101c8f51e516"},"execution_count":96,"outputs":[{"output_type":"stream","name":"stdout","text":["vocab_size=65\n","<S>\n","| |!|$|&|'|,|-|.|3|:|;|?|A|B|C|D|E|F|G|H|I|J|K|L|M|N|O|P|Q|R|S|T|U|V|W|X|Y|Z|a|b|c|d|e|f|g|h|i|j|k|l|m|n|o|p|q|r|s|t|u|v|w|x|y|z<E>\n"]}]},{"cell_type":"code","source":["# creating vocabulary and mapping and reverse mapping\n","itos = {i:c for i, c in enumerate(chars)}\n","stoi = {c:i for i, c in itos.items()}\n","encode = lambda s : [stoi[c] for c in s]\n","decode = lambda e : ''.join([itos[i] for i in e])\n","\n","sample_text = \"what's up\"\n","print(encode(sample_text))\n","print(decode(encode(sample_text)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qZYvlck2vTmv","executionInfo":{"status":"ok","timestamp":1718101483078,"user_tz":-480,"elapsed":12,"user":{"displayName":"Palash","userId":"17952405708644180763"}},"outputId":"f2bd9339-a70c-42f6-a039-163915caa419"},"execution_count":97,"outputs":[{"output_type":"stream","name":"stdout","text":["[61, 46, 39, 58, 5, 57, 1, 59, 54]\n","what's up\n"]}]},{"cell_type":"markdown","source":["## few notes about tokenizer usage"],"metadata":{"id":"GnMcPnz5_hkE"}},{"cell_type":"markdown","source":["Try other encodings as well.\n","e.g.\n","* SentencePiece\n","* Also BPE's fast implementation is tiktoken used in GPT models created by OpenAI\n","* OpenAI's tokenizer demo - https://platform.openai.com/tokenizer\n","* Third party tokenizer demo - https://tiktokenizer.vercel.app/\n","* tiktoken repo - https://github.com/openai/tiktoken\n","* sample tiktoken usage cookbook - https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb\n","\n","\n","---\n","\n","\n","**ToDo** - Learn about BPE tokenizer process in depth."],"metadata":{"id":"nWqRgSsS6biK"}},{"cell_type":"code","source":["#!pip install tiktoken\n","import tiktoken\n","enc = tiktoken.get_encoding('gpt2')\n","print(enc.n_vocab)\n","print(enc.encode(sample_text))\n","print(enc.decode(enc.encode(sample_text)))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TOcDq4Er46kE","executionInfo":{"status":"ok","timestamp":1718101483078,"user_tz":-480,"elapsed":12,"user":{"displayName":"Palash","userId":"17952405708644180763"}},"outputId":"819dc0e8-8e24-4958-c69f-a42fc52241a5"},"execution_count":98,"outputs":[{"output_type":"stream","name":"stdout","text":["50257\n","[10919, 338, 510]\n","what's up\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"sUgylD5JYxNg"}},{"cell_type":"markdown","source":["## data processing continued (with character encoding)"],"metadata":{"id":"rmHwT5_s_yR3"}},{"cell_type":"code","source":["import torch\n","#encode text into token\n","data = torch.tensor(encode(text), dtype=torch.long)\n","print(f\"{data.shape=}, {data.dtype=}\")\n","print(data[:100])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N-823NrI61ZN","executionInfo":{"status":"ok","timestamp":1718101483078,"user_tz":-480,"elapsed":11,"user":{"displayName":"Palash","userId":"17952405708644180763"}},"outputId":"a52796b5-a411-4585-b25b-909f7f88dc31"},"execution_count":99,"outputs":[{"output_type":"stream","name":"stdout","text":["data.shape=torch.Size([1115394]), data.dtype=torch.int64\n","tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n","        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n","         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n","        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n","         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n","        58, 47, 64, 43, 52, 10,  0, 37, 53, 59])\n"]}]},{"cell_type":"code","source":["# train, val split\n","split = int(0.9*len(data))\n","train_data = data[:split]\n","val_data = data[split:]\n","print(f\"{train_data.shape=}, {val_data.shape=}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b_-0L4pwBB01","executionInfo":{"status":"ok","timestamp":1718101483078,"user_tz":-480,"elapsed":10,"user":{"displayName":"Palash","userId":"17952405708644180763"}},"outputId":"6d23d77e-adac-40fa-d9b9-ad147eb070b7"},"execution_count":100,"outputs":[{"output_type":"stream","name":"stdout","text":["train_data.shape=torch.Size([1003854]), val_data.shape=torch.Size([111540])\n"]}]},{"cell_type":"code","source":["# get batches of data in block_size\n","\n","block_size = 8 # also called as context length\n","batch_size = 4 # for parallel processing\n","\n","torch.manual_seed(1337)\n","def get_batch(split):\n","  data = train_data if split=='train' else val_data\n","  batch_ixs = torch.randint(0, len(data) - block_size, (batch_size,))\n","  x = torch.stack([data[ix : ix + block_size] for ix in batch_ixs])\n","  y = torch.stack([data[ix + 1: ix + 1 + block_size] for ix in batch_ixs])\n","  '''\n","  if x indices are  [3,4,5,6,7,8,9, 10]\n","  y indices will be [4,5,6,7,8,9,10,11]\n","\n","  torch.stack will just stack in one extra dimension in front\n","  '''\n","  return x, y\n","\n","xb, yb = get_batch('train')\n","print(f\"{xb.shape=}, {yb.shape=}\")\n","print(xb)\n","print(yb)\n","\n","for bt in range(batch_size):\n","  for bl in range(block_size):\n","    context = xb[bt, :bl+1]\n","    output  = yb[bt, bl]\n","    print(f\"{decode(context.numpy())} --> {decode([output.item()])}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gqyZz2JiA-Qh","executionInfo":{"status":"ok","timestamp":1718101483078,"user_tz":-480,"elapsed":8,"user":{"displayName":"Palash","userId":"17952405708644180763"}},"outputId":"b4a08d17-34ed-42b0-9b2b-234b909c6947"},"execution_count":101,"outputs":[{"output_type":"stream","name":"stdout","text":["xb.shape=torch.Size([4, 8]), yb.shape=torch.Size([4, 8])\n","tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n","        [44, 53, 56,  1, 58, 46, 39, 58],\n","        [52, 58,  1, 58, 46, 39, 58,  1],\n","        [25, 17, 27, 10,  0, 21,  1, 54]])\n","tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n","        [53, 56,  1, 58, 46, 39, 58,  1],\n","        [58,  1, 58, 46, 39, 58,  1, 46],\n","        [17, 27, 10,  0, 21,  1, 54, 39]])\n","L --> e\n","Le --> t\n","Let --> '\n","Let' --> s\n","Let's -->  \n","Let's  --> h\n","Let's h --> e\n","Let's he --> a\n","f --> o\n","fo --> r\n","for -->  \n","for  --> t\n","for t --> h\n","for th --> a\n","for tha --> t\n","for that -->  \n","n --> t\n","nt -->  \n","nt  --> t\n","nt t --> h\n","nt th --> a\n","nt tha --> t\n","nt that -->  \n","nt that  --> h\n","M --> E\n","ME --> O\n","MEO --> :\n","MEO: --> \n","\n","MEO:\n"," --> I\n","MEO:\n","I -->  \n","MEO:\n","I  --> p\n","MEO:\n","I p --> a\n"]}]},{"cell_type":"markdown","source":["# lets start with simple bigram model"],"metadata":{"id":"1kcJfAchbKmt"}},{"cell_type":"markdown","source":["learn more about torch libraries - specifically start with nn.Module"],"metadata":{"id":"q-byeANNbuzG"}},{"cell_type":"code","source":["xb.shape, yb.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Iu0kE2g4fjFx","executionInfo":{"status":"ok","timestamp":1718101483461,"user_tz":-480,"elapsed":388,"user":{"displayName":"Palash","userId":"17952405708644180763"}},"outputId":"8f6042d8-22e6-4394-e0d4-10c56463e34d"},"execution_count":102,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([4, 8]), torch.Size([4, 8]))"]},"metadata":{},"execution_count":102}]},{"cell_type":"code","source":["import torch.nn as nn\n","import torch.nn.functional as F\n","class BigramLanguageModel(nn.Module):\n","  def __init__(self, vocab_size):\n","    super().__init__()\n","    self.token_embedding = nn.Embedding(vocab_size, vocab_size)\n","\n","  def forward(self, x, targets):\n","    logits = self.token_embedding(x) # converts shape(B, T) to shape(B, T, C) | B-batch, T-?, C-Channel(Embedding_size)\n","    B,T,C = logits.shape\n","    # read documentation of cross_entropy for reason of this reshaping -\n","    # https://pytorch.org/docs/stable/generated/torch.nn.functional.cross_entropy.html#torch.nn.functional.cross_entropy\n","    logits = logits.view(B*T, C)\n","    targets = targets.view(B*T) # or just -1\n","    loss = F.cross_entropy(logits, targets)\n","\n","    return logits, loss\n","\n","model = BigramLanguageModel(vocab_size)\n","logits, loss = model(xb, yb)\n","print(f\"{logits=}, {loss=}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hlhVMLYOUWWI","executionInfo":{"status":"ok","timestamp":1718101483461,"user_tz":-480,"elapsed":3,"user":{"displayName":"Palash","userId":"17952405708644180763"}},"outputId":"1c88854f-30ef-4723-ef84-dcc431b12181"},"execution_count":103,"outputs":[{"output_type":"stream","name":"stdout","text":["logits=tensor([[ 1.6347, -0.0518,  0.4996,  ...,  0.2432,  1.1519,  0.9950],\n","        [ 0.3418, -0.9276,  1.2381,  ...,  1.5018, -0.5266,  0.2354],\n","        [ 0.1479, -0.4333,  0.5203,  ...,  0.3302,  1.5454,  1.3778],\n","        ...,\n","        [-0.5693, -0.0735,  0.7743,  ..., -0.0815, -1.1445, -0.0623],\n","        [ 0.4658, -0.2573, -1.0673,  ...,  1.2439,  1.3471,  1.6910],\n","        [-0.4553,  0.0139,  0.9309,  ...,  0.0290, -0.7568,  0.8701]],\n","       grad_fn=<ViewBackward0>), loss=tensor(5.0364, grad_fn=<NllLossBackward0>)\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"4m1dE7GHb3Oj","executionInfo":{"status":"ok","timestamp":1718101483461,"user_tz":-480,"elapsed":1,"user":{"displayName":"Palash","userId":"17952405708644180763"}}},"execution_count":103,"outputs":[]}]}